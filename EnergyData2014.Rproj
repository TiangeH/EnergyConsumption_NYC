Version: 1.0

RestoreWorkspace: Default
SaveWorkspace: Default
AlwaysSaveHistory: Default

EnableCodeIndexing: Yes
UseSpacesForTab: Yes
NumSpacesForTab: 2
Encoding: UTF-8

RnwWeave: Sweave
LaTeX: pdfLaTeX

#1.import data
nyc_data_2016<-read.csv(file = "C:/Users/Tiange/Desktop/Capstone_Project/2016NYC.csv",header = T,sep=',')
nyc_data<-read.csv(file = "C:/Users/Tiange/Desktop/Capstone_Project/nyc_2014_raw.csv",header = T,sep=',')

#to see the data
str(nyc_data)
table(nyc_data$Borough)
Summary(nyc_data)

#2. install packages and rename the data since many attributes' name is not convenient for us to use
install.packages("gtools")#for quantcut function
library(gtools) #for quantcut
library(sqldf)
library(ggplot2)
library(randomForest)
library(data.table)


colnames(nyc_data)<-c("RecordNumber",
                      "BBL",
                      "Co_BBLStatus",
                      "BBLsCo_reported",
                      "BIN",
                      "StreetNumber",
                      "StreetName",
                      "Borough",
                      "ZipCode",
                      "BBLontheCoveredBuildingsList",
                      "DOFBenchmarkingSubmissionStatus",
                      "SiteEUI_kBtu_ft2",
                      "WeatherNormalizedSiteEUI_kBtu_ft2","SourceEUIkBtu_ft2",
                      "WeatherNormalizedSourceEUIkBtu_ft2",
                      "MunicipallySuppliedPotableWater_IndoorIntensity_gal_ft",
                      "AutomaticWaterBenchmarkingEligible",
                      "ReportedWaterMethod",
                      "ENERGYSTARScore",
                      "TotalGHGEmissions_MtCO2e",
                      "DirectGHGEmissions_MtCO2e",
                      "IndirectGHGEmissions_MtCO2e",
                      "ReportedPropertyFloorArea_Buildings_ft",
                      "DOFPropertyFloorArea_BuildngsandParking_ft2",
                      "PrimaryPropertyType",
                      "DOFNumberofBuildings")
                      
#change factor to numeric for further analysis, this can be done by for loop to save time
nyc_data$RecordNumber<-as.numeric(nyc_data$RecordNumber)
nyc_data$SiteEUI_kBtu_ft2<-as.numeric(as.character(nyc_data$SiteEUI_kBtu_ft2))
nyc_data$WeatherNormalizedSiteEUI_kBtu_ft2<-as.numeric(as.character(nyc_data$WeatherNormalizedSiteEUI_kBtu_ft2))
nyc_data$SourceEUIkBtu_ft2<-as.numeric(as.character(nyc_data$SourceEUIkBtu_ft2))
nyc_data$WeatherNormalizedSourceEUIkBtu_ft2<-as.numeric(as.character(nyc_data$WeatherNormalizedSourceEUIkBtu_ft2))
nyc_data$MunicipallySuppliedPotableWater_IndoorIntensity_gal_ft<-as.numeric(as.character(nyc_data$MunicipallySuppliedPotableWater_IndoorIntensity_gal_ft))
nyc_data$ENERGYSTARScore<-as.numeric(as.character(nyc_data$ENERGYSTARScore))
nyc_data$TotalGHGEmissions_MtCO2e<-as.numeric(as.character(nyc_data$TotalGHGEmissions_MtCO2e))
nyc_data$DirectGHGEmissions_MtCO2e<-as.numeric(as.character(nyc_data$DirectGHGEmissions_MtCO2e))
nyc_data$IndirectGHGEmissions_MtCO2e<-as.numeric(as.character(nyc_data$IndirectGHGEmissions_MtCO2e))
nyc_data$ReportedPropertyFloorArea_Buildings_ft<-as.numeric(as.character(nyc_data$ReportedPropertyFloorArea_Buildings_ft))
nyc_data$DOFPropertyFloorArea_BuildngsandParking_ft2<-as.numeric(as.character(nyc_data$DOFPropertyFloorArea_BuildngsandParking_ft2))


#3.because our goal is to get the most relevant features of energy score and do a prediction model, we need to understand our 
   energy score first
   
hist(nyc_data$ENERGYSTARScore)

#We have 4985 rows of "Not Available" and 483 rows with "See Primary BBL".
#we need to know if these rows contain other important information

#create a data frame that EnergyStarScore is "Not Available" in case use later
noscore<-sqldf('select* from nyc_data where ENERGYSTARScore == "Not Available"')
noscore[ noscore == "Not Available" | noscore == "" ] <- NA
na_count_row_noscore<- apply(noscore, 1, function(x) sum(is.na(x))) 

#remove those with In Violation because those rwos contains most missing value
nyc_data<-sqldf("select * from nyc_data 
                where DOFBenchmarkingSubmissionStatus != 'In Violation ' 
                 and DOFBenchmarkingSubmissionStatus!= 'Not Applicable' 
                 and ENERGYSTARScore != 'Not Available' 
                 and ENERGYSTARScore!= '0'
                 and ENERGYSTARScore!='See Primary BBL'
                ")
#we use the levels to check and found we still have the "Not Available", 
#use which(nyc_data$ENERGYSTARScore =="Not Available" , arr.ind=TRUE)
#to check and didn't find it, 
which(nyc_data$ENERGYSTARScore =="Not Available" , arr.ind=TRUE)

#check the distribution of EnergyScore
hist(nyc_data$ENERGYSTARScore)

#in our data, we find that we have two categorical variables are important
#borough and primary building type.

#check the Borough
table(nyc_data$Borough)
property_type<-sqldf("select count (*),PrimaryPropertyType from nyc_data group by PrimaryPropertyType order by count(*) desc")
borough_tyoe<- sqldf("select count (*),Borough from nyc_data group by Borough order by count(*) desc")

#to visualize the categorial data and energy score,borough and building usage purpose
library(ggplot2)
ggplot(nyc_data) + geom_density(aes(x = ENERGYSTARScore, color =Borough))
ggplot(nyc_data) + geom_density(aes(x = ENERGYSTARScore, fill =Borough), alpha = 0.2)

#check the primary building type
ggplot(nyc_data) + geom_density(aes(x = ENERGYSTARScore, fill =PrimaryPropertyType), alpha = 0.2)



#important numeric attributes are as below, in the orginal dataframe.

#as we can see, a lot attributes are highly correlated with each other. For example
#siteEUi and WeatherNormalizedSiteEui.Based on the defiinition on BenchLaw84
#weatherNormalizeSiteEui represent the mean of siteEUi when weather change.
#however, it may not has huge effect for large size building. 
#since then, we have two methods to deal with these.
#As we checked, we have a lot missing WeatherNormalizedSite and WeatherNormalizedSourceEUI
#1st method is remove WeaNormSour and WeaNorSit EUi form our frame
#2nd is replace missing vlaue in WeaNormSour and WeaNorSit by site and sourceEUI.

cor.test(nyc_data$SiteEUI_kBtu_ft2,nyc_data$WeatherNormalizedSiteEUI_kBtu_ft2)
#there is 99.99% correlation between SiteEUI and WeatherNormalizeSite EUI
#if we use the summary or quantcut function, we can find that 1/3 of data
#has site EUI larger than 107, we will seperate them and compare correlationship
#between SiteEUI and WeatherNormalizedSiteEUI

nn_l_107<-nyc_data[(nyc_data[,14]>107),]
nn_s_107<-nyc_data[(nyc_data[,14]<=107),]
 
 plot(nn_s_107$SiteEUI_kBtu_ft2, nn_s_107$WeatherNormalizedSiteEUI_kBtu_ft2, main="SiteEUI&WeatherNormalizedSiteEui", 
     xlab="SiteEUI ", 
     ylab="WeatherNormalizedSiteEUI ",col=c("green","blue"), pch=19) 

plot(nn_s_107$SourceEUIkBtu_ft2, nn_s_107$WeatherNormalizedSourceEUIkBtu_ft2, main="SourceEUI&WeatherNormalizedSourceEui", 
     xlab="SourceEUI ", 
     ylab="WeatherNormalizedSourceEUI ",col=c("green","blue"), pch=19)

#Since SiteEUI and WeatherNormalizedSiteEUI, SouceEUI and WeatherNormalizedSourceEUI are hight correlated. There are a lot missing values in 
#WeatehrNormalizedSite/Souce EUI. I am going to keep SiteEUI and SourceEUI.

#then we compare SiteEUI and SourceEUI
plot(nn_s_107$SiteEUI_kBtu_ft2, nn_s_107$SourceEUIkBtu_ft2, main="SiteEUI&SourceEui", 
     xlab="SiteEUI ", 
     ylab="SourceEUI ", pch=19)

SourceEUI and SiteEUI also highly correlated, we will keep SiteEUI.

#only keep attributes that we need to use



nn<-sqldf("select 
          ENERGYSTARScore,
          SiteEUI_kBtu_ft2,
          TotalGHGEmissions_MtCO2e,
          ReportedPropertyFloorArea_Buildings_ft, 
          PrimaryPropertyType,
          Borough
          from nyc_data 
          where
          ENERGYSTARScore >1 and ENERGYSTARScore < 100
          and SiteEUI_kBtu_ft2 >= 69 and SiteEUI_kBtu_ft2 <=152
          and TotalGHGEmissions_MtCO2e >=370 and TotalGHGEmissions_MtCO2e <= 1313
          and ReportedPropertyFloorArea_Buildings_ft >=67848 and ReportedPropertyFloorArea_Buildings_ft<= 502054")

#the value range is inside the 1st quantile and 3rd quantile of each attributes
#In the new data.frame nn, we only have 6 attribute, 2 of them are categories
#borough, primary building type categorical
#SiteEUI, EnergyStore, MunicipallySuppliedWaterIntensity,ReportedFloorArea


#study notes for how to subset certain value range from a data frame
#rr_e<-subset(rr,rr$TotalGHGEmissions_MtCO2e >= 370 & rr$TotalGHGEmissions_MtCO2e <= 1313)

#scale data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x))) }
prc_n <- as.data.frame(lapply(nn[2:5], normalize))

boxplot(prc_n, main='Original Data')

#put energy start score into 6 different groups
qq<-quantcut(nn$ENERGYSTARScore,q=6)

nn$ENERGYSTARScore[nn$ENERGYSTARScore>=1 & nn$ENERGYSTARScore <=19] <- "1"
nn$ENERGYSTARScore[nn$ENERGYSTARScore>=20 & nn$ENERGYSTARScore <=42] <- "2"
nn$ENERGYSTARScore[nn$ENERGYSTARScore>=43 & nn$ENERGYSTARScore <=59] <- "3"
nn$ENERGYSTARScore[nn$ENERGYSTARScore>=60 & nn$ENERGYSTARScore <=74] <- "4"
nn$ENERGYSTARScore[nn$ENERGYSTARScore>=75 & nn$ENERGYSTARScore <=88] <- "5"
#nn$ENERGYSTARScore[nn$ENERGYSTARScore>88 & nn$ENERGYSTARScore <=101] <- "6"
nn$ENERGYSTARScore[nn$ENERGYSTARScore %in% c("89","90","91","92","93","94","95","96","97","98","99","100")] <- "6"


nn$ENERGYSTARScore<-as.factor(nn$ENERGYSTARScore)

dt = sort(sample(nrow(nn), nrow(nn)*.7))
train_d<-nn[dt,]
test_d<-nn[-dt,]
dim(train_d)
dim(test_d)


library(randomForest)

output_forest <- randomForest(ENERGYSTARScore ~ SiteEUI_kBtu_ft2+
                                TotalGHGEmissions_MtCO2e+
                                ReportedPropertyFloorArea_Buildings_ft,
                              data = train_d,ntree=400, mtry=3,
                              importance=TRUE)
 
plot(output_forest)
importance(output_forest) 
pred <- predict(output_forest, newdata = test_d)
table(pred, test_d$ENERGYSTARScore)




